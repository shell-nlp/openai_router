
<!-- markdownlint-disable MD033 -->
<h1 align="center">
ğŸš€ OpenAI Router 
</h1>
 
<p align="center">
<b>è½»é‡çº§ã€æŒä¹…åŒ–ã€é›¶é…ç½®çš„ OpenAI API ç»Ÿä¸€ç½‘å…³</b><br>
ä¸€é”®èšåˆ vLLMã€SGLangã€lmdeployã€Ollamaâ€¦  
</p>
 
<p align="center">
<a href="#"><img src="https://img.shields.io/badge/license-MIT-blue?style=flat-square"></a>
<a href="https://fastapi.tiangolo.com"><img src="https://img.shields.io/badge/FastAPI-v0.115+-teal?style=flat-square"></a>
<a href="https://gradio.app"><img src="https://img.shields.io/badge/Gradio-v5+-orange?style=flat-square"></a>
<a href="#"><img src="https://img.shields.io/badge/SQLite-å†…ç½®å­˜å‚¨-lightgrey?style=flat-square"></a>
<a href="https://pypi.org/project/openai-router/"><img  src="https://img.shields.io/pypi/v/openai-router?style=flat-square&logo=pypi&label=PyPI"></a> 
</p>
 
---
 
## âœ¨ Features 
| Feature | Description |
|---------|-------------|
| ğŸŒ ç»Ÿä¸€å…¥å£ | `/chat/completions`ã€`/embeddings`ã€`/images/generations`â€¦ å…¨éƒ¨è½¬å‘ |
| ğŸ§© å¤šåç«¯ | vLLMã€SGLangã€lmdeployã€Ollamaâ€¦ ä»»æ„ç»„åˆ |
| ğŸ’¾ æŒä¹…åŒ– | SQLite + SQLModel é›¶é…ç½®å­˜å‚¨è·¯ç”± |
| âš¡ å®æ—¶æµ | SSE & Chunked Transfer å…¨åŒå·¥æ”¯æŒ |
| ğŸ¨ Web UI | Gradio å³ç”¨çš„ç®¡ç†é¢æ¿ |
| ğŸ” å…¼å®¹ OpenAI | SDK / LangChain / AutoGen / LlamaIndex / CrewAI  â€¦ç­‰ **ä¸€è¡Œä»£ç éƒ½ä¸ç”¨æ”¹** |
 
---
 
## ğŸ“¦ Quick Start 
### Step-1ï¼šå®‰è£… 

#### PyPIï¼ˆæ¨èï¼‰

```bash 
uv add openai-router -U
```
æˆ–è€…
```bash 
pip install openai-router -U
```


 
### Step-2ï¼šå¯åŠ¨ 
```bash 
openai-router --host localhost --port 8000 
```
æµè§ˆå™¨è‡ªåŠ¨æ‰“å¼€  
ğŸ“ UIï¼š`http://localhost:8000`  
ğŸ“ APIï¼š`http://localhost:8000/v1`
 
Step-3ï¼šæ·»åŠ åç«¯ 
åœ¨ Web UI ã€Œæ·»åŠ  / æ›´æ–°ã€å¡«å…¥ï¼š
- æ¨¡å‹åï¼š`gpt-4`
- åç«¯ URLï¼š`http://localhost:8080/v1`
 
<img src="static/ui.png" width="800">
 
---
 
## ğŸ”§ API Usage 
### **åƒå®˜æ–¹ OpenAI SDKä¸€æ ·è°ƒç”¨**
```python 
from openai import OpenAI 
client = OpenAI(
      base_url="http://localhost:8000/v1",
      api_key="sk-dummy"
)
resp = client.chat.completions.create(
      model="gpt-4",
      messages=[{"role":"user","content":"hello"}],
      stream=True 
)
for chunk in resp:
      print(chunk.choices[0].delta.content or "", end="")
```
 
cURL 
```bash 
curl http://localhost:8000/v1/chat/completions \
     -H "Content-Type: application/json" \
     -d '{"model":"gpt-4","messages":[{"role":"user","content":"hi"}],"stream":true}'
```
 
---
 
## ğŸ—‚ï¸ Endpoints 
| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/` | Gradio Admin UI |
| `GET` | `/docs` | OpenAPI Swagger |
| `GET` | `/v1/models` | List available models |
 `POST` | `/v1/responses` | Responses API |
| `POST` | `/v1/chat/completions` | Chat completion |
| `POST` | `/v1/embeddings` | Text embeddings |
| `POST` | `/v1/images/generations` | DALLÂ·E style |
| `POST` | `/v1/audio/transcriptions` | Whisper |
| â€¦ | â€¦ | All OpenAI endpoints supported |
 
---
 
## âš™ï¸ Configuration 
CLI Options 
```bash 
python -m openai_router.main --help 
```
| Flag | Default | Description |
|------|---------|-------------|
| `--host` | `localhost` | Bind address |
| `--port` | `8000` | Bind port |
 

---
 
## ğŸ—ï¸ Architecture 
<img src="static/arch.png" width="800">